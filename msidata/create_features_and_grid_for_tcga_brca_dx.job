#!/bin/bash

#SBATCH --job-name=create_grid
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --partition=normal
#SBATCH --ntasks=1
#SBATCH --time=2:0:0

module purge
module load 2019

module load Anaconda3
module load CUDA/10.0.130
module load cuDNN/7.6.3-CUDA-10.0.130
export LD_LIBRARY_PATH=/hpc/eb/Debian9/cuDNN/7.6.3-CUDA-10.0.130/lib64:$LD_LIBRARY_PATH

CONDA_PREFIX=$(conda info --base)
source $CONDA_PREFIX/etc/profile.d/conda.sh
conda deactivate
conda activate thesisp375_apex # has pytorch 1.6 instead of 1.4
cd ..
#srun python -m msidata.save_feature_vectors with config_file=./config/config-create-features-and-grid-brca-dx.yaml batch_size=1024 workers=0 path_to_msi_data=/home/yonis/histogenomics-msc-2019/yoni-code/MsiPrediction/metadata/tcga/brca_dx/data_tcga_brca_dxwith_ddr_labels_and_splits_dropna.csv use_precomputed_features=True use_precomputed_features_id=585  # compute and save all feature vectors. aggregate all into large feature grids

srun python -m msidata.save_feature_vectors with config_file=./config/config-create-features-and-grid-brca-dx.yaml use_precomputed_features=True workers=0 use_precomputed_features_id=585 path_to_msi_data=/home/yonis/histogenomics-msc-2019/yoni-code/MsiPrediction/metadata/tcga/brca_dx/data_tcga_brca_dxwith_ddr_labels_and_splits_dropna_subsample_500.csv # aggregate subset into smaller feature grids

