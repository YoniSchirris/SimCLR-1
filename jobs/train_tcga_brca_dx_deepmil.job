#!/bin/bash

#SBATCH --job-name=batched_deepmil
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=4
#SBATCH --partition=gpu_shared
#SBATCH --ntasks=1
#SBATCH --gres=gpu:1
#SBATCH --time=0:59:0
#SBATCH --array=1-5
# moved into jobs/msi dir, nothing should change besides this

module purge
module load 2019

module load Anaconda3
module load CUDA/10.0.130
module load cuDNN/7.6.3-CUDA-10.0.130
export LD_LIBRARY_PATH=/hpc/eb/Debian9/cuDNN/7.6.3-CUDA-10.0.130/lib64:$LD_LIBRARY_PATH

CONDA_PREFIX=$(conda info --base)
source $CONDA_PREFIX/etc/profile.d/conda.sh
conda deactivate
conda activate thesisp375_apex

cd ..

srun python3 -u -m testing.logistic_regression with config_file=./config/train-deepmil-brca-dx-batch-hrd.yaml logistic_batch_size=16 evaluate_every=3 ddr_label=median_HRD_Score kfold=$SLURM_ARRAY_TASK_ID


#srun python3 -u train.py --single_gpu --name=stadlr56 --batch_size=256 --run_times=3 --epochs=100 --freeze_num=0 --evaluate_every=256 --eval_patience=3 --data=msidata/stad --save_model=True --track_tb=True --learning_rate=5e-6 --weight_decay=1e-4 --learning_rate_factor=2 --seedstart=1
