{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "# sys.path.append('../../')\n",
    "sys.path.append('./')\n",
    "# importing the python Slidescore API client\n",
    "from slidescore_utils import APIClient\n",
    "# from .slidescore import APIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The annotation is a list of strings that follow the format:\n",
    "# ImageID\\tImageName\\tBy\\tQuestion\\tAnswer\n",
    "# for the Heatmap, the answer has to follow the format:\n",
    "# { \"type\": \"heatmap\", \"x\": int, \"y\": int, \"height\": int, \"width\": int, data\": [[255,0,0],[0,255,0],[0,0,255]]\n",
    "# x, y are the coordinates of the top left corner of the heatmap area (if not specified this will be (0, 0))\n",
    "# width & height are the stretch target of the heatmap data, if left unspecified the default value is the dimentions of the slide\n",
    "# x, y, width, and height are specificed at the level 0 resolution (maximum mpp)\n",
    "# if x, and y are greater than zero but width and height (repectively) are not specified, the data will be streched only to the bottom right corner of the image\n",
    "# with open('heatmap_results_copy.txt', 'r') as f:\n",
    "#     heatmap_annotation = f.readlines()[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the sample heatmap annotation from https://www.slidescore.com/Studies/Details/9\n",
    "# heatmap_dict = json.loads(heatmap_annotation.split('\\t')[-1])[0]\n",
    "# # heatmap_dict['x'], heatmap_dict['y'], heatmap_dict['height'] \n",
    "# h = np.array(heatmap_dict['data'])\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.imshow(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the Slidescore API client\n",
    "url = \"https://rhpc.nki.nl/slidescore\"\n",
    "# apitoken = open('yoni_key/siamak_bod_api.txt', 'r').read().strip()\n",
    "apitoken = open('./keys/key_study_777.txt', 'r').read().strip()\n",
    "url = \"https://rhpc.nki.nl/slidescore\"\n",
    "\n",
    "client = APIClient(url, apitoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.get_image_metadata(77939)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## These were used as test\n",
    "\n",
    "# # WSIs displayed in the thesis report for BASIS, also used to show the visualization of tiles used\n",
    "# wsi_paths = [\"/project/schirris/tiled_data_large/case-PD9064a/pid_YID057_tile_grid_extractor_585.pt\",\n",
    "# \"/project/schirris/tiled_data_large/case-PD4962a/pid_YID155_tile_grid_extractor_585.pt\",\n",
    "# \"/project/schirris/tiled_data_large/case-PD11386a/pid_YID165_tile_grid_extractor_585.pt\",\n",
    "# \"/project/schirris/tiled_data_large/case-PD13755a/pid_YID247_tile_grid_extractor_585.pt\"]\n",
    "\n",
    "# slidescore_im_ids = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# slidescore_im_ids = [71651, 71812, 71735, 71771]\n",
    "# slidescore_slide_ids = [\"PD9064a-2011-05-26_17.55.05\", \"PD4962a_Frozen_H_E_181208-2011-06-09_14.18.05\", \"PD11386a_HE-2014-12-06_08.41.11\", \"PD13755a_1_HE-2012-10-02_21.23.39\"]\n",
    "\n",
    "# slidescore_im_id = slidescore_im_ids[3]\n",
    "# slidescore_slide_id = slidescore_slide_ids[3]\n",
    "# wsi_path = wsi_paths[3]\n",
    "\n",
    "# # attention_output_file = \"attention_output_epoch_17_2020-10-09-16-24-37.csv\"\n",
    "\n",
    "\n",
    "# current_case = wsi_path.split('/')[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here are the tiles that we actually use\n",
    "\n",
    "# Used as the first test ever: \"./pid_YID028_tile_grid_extractor_585.pt\"\"\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# df = pd.read_csv(attention_output_file)\n",
    "# df['pd'] = df.apply(lambda x: x['tile_name'].split('/')[4] if x['tile_name'] != 'tensor(nan)' else 'a', axis=1)\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(attention_output_file)\n",
    "df['pd'] = df.apply(lambda x: x['tile_name'].split('/')[4] if x['tile_name'] != 'tensor(nan)' else 'a', axis=1)\n",
    "df.head()\n",
    "\n",
    "def fake_increase_res(tile):\n",
    "    upsample_factor = 5\n",
    "    new_tile = torch.zeros((tile.shape[0]*upsample_factor, tile.shape[1]*upsample_factor))\n",
    "    print(f\"Old tile shape: {tile.shape}, new tile shape: {new_tile.shape}\")\n",
    "    for i in range(tile.shape[0]):\n",
    "        for j in range(tile.shape[1]):\n",
    "            new_tile[i*upsample_factor:i*upsample_factor+upsample_factor-1, j*upsample_factor:j*upsample_factor+upsample_factor-1] = tile[i,j]\n",
    "    return new_tile, upsample_factor\n",
    "\n",
    "def get_attention(current_case, attention_file, wsi_path, attention_type):\n",
    "    print(\"In get_attention...\")\n",
    "    ## Getting the tile...\n",
    "    feature_grid = torch.load(wsi_path, map_location='cpu')\n",
    "    used_tiles = feature_grid.clone().detach()\n",
    "    used_tiles[((used_tiles.float().std(dim=2) != 0) | (used_tiles.sum(dim=2) != 0))] = 255\n",
    "    used_tiles = used_tiles.mean(dim=2).int()\n",
    "    \n",
    "    ## Getting the attentions...\n",
    "    \n",
    "    \n",
    "    subdf = df[df['pd']==f'case-{current_case}']\n",
    "\n",
    "    value_tiles = used_tiles.clone().detach().float()\n",
    "    \n",
    "\n",
    "    def set_tile(tile, x, y, val):\n",
    "        tile[x][y] = val\n",
    "\n",
    "    \n",
    "    print(f\"Shape of the tiled WSI: {value_tiles.shape}\")\n",
    "\n",
    "    \n",
    "        \n",
    "    print(f\"The attention of the current patient looks like : {subdf[attention_type].describe()}\")\n",
    "        \n",
    "    subdf.apply(lambda x: set_tile(value_tiles, int(x['x']), int(x['y']), x[attention_type]), axis=1)\n",
    "    \n",
    "    print(f\"After setting values in the tile, value_tiles looks like {value_tiles.mean()}\")\n",
    "    \n",
    "    \n",
    "#     subdf.apply(lambda x: set_tile(gradient_tile, int(x['x']), int(x['y']), x['attention_gradients'] if x['attention_gradients'] > 0 else 0), axis=1)\n",
    "\n",
    "\n",
    "#     attention_tile = gradient_tile.clone().detach()\n",
    "    # for index, row in subdf.iterrows():\n",
    "\n",
    "    #     attention_tile[int(row['x'])][int(row['y'])] = row['attention']\n",
    "\n",
    "    \n",
    "    min_attention = value_tiles.min()\n",
    "\n",
    "    print(\"Rescaling values so that the max attention is set to 255\")\n",
    "    value_tiles += np.abs(min_attention)\n",
    "    \n",
    "    max_attention = value_tiles.max()\n",
    "\n",
    "    print(f\"max attention: {max_attention}\")\n",
    "    value_tiles = value_tiles * (255/max_attention)\n",
    "    \n",
    "    print(used_tiles==255)\n",
    "    value_tiles[used_tiles!=255]=0 # Set the values for unseen tiles to 0\n",
    "    # attention_tile[attention_tile > 0] += 110\n",
    "\n",
    "    value_tiles = value_tiles.int()\n",
    "    \n",
    "    value_tiles, upsample_factor = fake_increase_res(value_tiles)\n",
    "    \n",
    "    return value_tiles, upsample_factor\n",
    "    \n",
    "\n",
    "    # attention_tile=[[255,0,255], [0,255,0], [255,0,255]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"yschirris@gmail.com\"\n",
    "ann_name=\"yoni_heatmap_attention_hrd\"\n",
    "study_id=777\n",
    "\n",
    "\n",
    "def create_custom_heatmap_annotation(current_case, slidescore_im_id, attention_file, wsi_path, attention_type, tilejson_path):\n",
    "    ann_name=f\"yoni_heatmap_{attention_type if attention_type == 'attention' else 'gradient'}_hrd\"\n",
    "\n",
    "    print(\"In ceeate custom heatmap annotation...\")\n",
    "    im_id = slidescore_im_id\n",
    "    \n",
    "    meta = client.get_image_metadata(im_id)\n",
    "    name = meta['fileName']\n",
    "    \n",
    "    #TODO Check where to start with x, y, and what the height ,and width should be\n",
    "    # use gheight and gwidth for this from the tile.json\n",
    "    height=meta['level0Height'] # e.g. tile.shape[0] * gwidth, or something\n",
    "    width=meta['level0Width']\n",
    "    \n",
    "#    \"max_res_width\": 1128.0,\n",
    "#     \"max_res_height\": 1128.0,\n",
    "    with open(tilejson_path, 'r') as f:\n",
    "        tilejson = json.load(f)\n",
    "    \n",
    "    mrw = tilejson['max_res_width']\n",
    "    mrh = tilejson['max_res_height']\n",
    "    \n",
    "\n",
    "    print(f\"Actual height and width of image: {height, width}\")\n",
    "\n",
    "    # nprand = (np.random.rand(int(height/255),int(width/255))*255).astype(int).tolist()\n",
    "    nprand=(np.random.rand(10, 10)*255).astype(int).tolist()\n",
    "\n",
    "    # data = [[255,0,255, 100, 100], [0,255,0, 100, 100], [255,0,255, 100, 100]]\n",
    "    # data=nprand\n",
    "    # data = tile\n",
    "    # data=attention_tile\n",
    "    # data=nprand\n",
    "#     data=used_tiles\n",
    "    data, upsample_factor = get_attention(current_case, attention_file, wsi_path, attention_type)\n",
    "    height = (data.shape[0]/upsample_factor)*mrh\n",
    "    width = (data.shape[1]/upsample_factor)*mrw\n",
    "    \n",
    "    print(f\"Our assumed height and width of the tile values: {height, width}\")\n",
    "    \n",
    "    data = data.tolist()\n",
    "    \n",
    "    ann_obj= [{ \"type\": \"heatmap\", \"width\": width, \"height\": height, \"data\": data }]\n",
    "\n",
    "    \n",
    "    \n",
    "    custom_heatmap_annotation = f'{im_id}\\t{name}\\t{user}\\t{ann_name}\\t{ann_obj}'.replace(\"\\'\", '\"')\n",
    "\n",
    "    return custom_heatmap_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We started by adding a shape annotation question to the study questions in slide score and we named it: Heatmap\n",
    "# when creating the annotation we also set the Question to Heatmap \n",
    "\n",
    "def upload_results(current_case, slidescore_im_id, attention_file, wsi_path, attention_type, tilejson_path):\n",
    "    print(\"In upload results...\")\n",
    "    \n",
    "    custom_heatmap_annotation = create_custom_heatmap_annotation(current_case, slidescore_im_id, attention_file, wsi_path, attention_type, tilejson_path)\n",
    "    \n",
    "    print(custom_heatmap_annotation[:110])\n",
    "    client.upload_results(study_id, [custom_heatmap_annotation]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (42496, 61440)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([73, 102])\n",
      "The attention of the current patient looks like : count    5.608000e+03\n",
      "mean     1.616190e-04\n",
      "std      5.197195e-04\n",
      "min      1.289583e-07\n",
      "25%      1.553390e-06\n",
      "50%      3.680746e-06\n",
      "75%      1.446152e-05\n",
      "max      5.655438e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 0.00012172429705969989\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.005655438173562288\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([73, 102]), new tile shape: torch.Size([365, 510])\n",
      "Our assumed height and width of the tile values: (41172.0, 57528.0)\n",
      "71717\tPD7217a_I9_HE-2013-01-31_17.25.04\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"w\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (42496, 61440)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([73, 102])\n",
      "The attention of the current patient looks like : count    5608.000000\n",
      "mean       -0.410002\n",
      "std         0.489172\n",
      "min        -2.085040\n",
      "25%        -0.757560\n",
      "50%        -0.576720\n",
      "75%         0.050612\n",
      "max         0.689479\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.3087954521179199\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 2.774519681930542\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([73, 102]), new tile shape: torch.Size([365, 510])\n",
      "Our assumed height and width of the tile values: (41172.0, 57528.0)\n",
      "71717\tPD7217a_I9_HE-2013-01-31_17.25.04\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"wi\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (80128, 110592)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([71, 98])\n",
      "The attention of the current patient looks like : count    3.933000e+03\n",
      "mean     7.985961e-05\n",
      "std      3.687540e-04\n",
      "min      4.296124e-07\n",
      "25%      5.282819e-06\n",
      "50%      1.886092e-05\n",
      "75%      4.765100e-05\n",
      "max      1.210968e-02\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 4.514053580351174e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.012109683826565742\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False,  True,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([71, 98]), new tile shape: torch.Size([355, 490])\n",
      "Our assumed height and width of the tile values: (80088.0, 110544.0)\n",
      "71762\tPD11366a_HE-2014-12-07_02.09.37\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (80128, 110592)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([71, 98])\n",
      "The attention of the current patient looks like : count    3933.000000\n",
      "mean       -0.793635\n",
      "std         0.653671\n",
      "min        -3.344433\n",
      "25%        -1.177924\n",
      "50%        -0.869119\n",
      "75%        -0.481708\n",
      "max         1.610249\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.44860127568244934\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 4.954681396484375\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False,  True,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([71, 98]), new tile shape: torch.Size([355, 490])\n",
      "Our assumed height and width of the tile values: (80088.0, 110544.0)\n",
      "71762\tPD11366a_HE-2014-12-07_02.09.37\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (72448, 77824)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([62, 66])\n",
      "The attention of the current patient looks like : count    2.542000e+03\n",
      "mean     7.999320e-05\n",
      "std      2.680580e-04\n",
      "min      5.470711e-07\n",
      "25%      7.359954e-06\n",
      "50%      1.696967e-05\n",
      "75%      5.269967e-05\n",
      "max      5.785988e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 4.9692742322804406e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.005785987712442875\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([62, 66]), new tile shape: torch.Size([310, 330])\n",
      "Our assumed height and width of the tile values: (69936.0, 74448.0)\n",
      "71635\tPD13422a_HE-2014-12-04_19.12.33\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (72448, 77824)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([62, 66])\n",
      "The attention of the current patient looks like : count    2542.000000\n",
      "mean       -0.877541\n",
      "std         0.742914\n",
      "min        -3.841054\n",
      "25%        -1.396516\n",
      "50%        -0.776906\n",
      "75%        -0.292950\n",
      "max         1.908364\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.5451390743255615\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 5.749418258666992\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([62, 66]), new tile shape: torch.Size([310, 330])\n",
      "Our assumed height and width of the tile values: (69936.0, 74448.0)\n",
      "71635\tPD13422a_HE-2014-12-04_19.12.33\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (86784, 110592)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([72, 97])\n",
      "The attention of the current patient looks like : count    1.341000e+03\n",
      "mean     3.430512e-05\n",
      "std      3.297877e-05\n",
      "min      8.097373e-07\n",
      "25%      1.477211e-05\n",
      "50%      2.460967e-05\n",
      "75%      4.304994e-05\n",
      "max      3.613023e-04\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 6.586935796804028e-06\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.00036130231455899775\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False,  True]])\n",
      "Old tile shape: torch.Size([72, 97]), new tile shape: torch.Size([360, 485])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our assumed height and width of the tile values: (81216.0, 109416.0)\n",
      "71794\tPD11352a_HE-2014-12-07_11.14.57\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (86784, 110592)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([72, 97])\n",
      "The attention of the current patient looks like : count    1341.000000\n",
      "mean       -1.857395\n",
      "std         1.713877\n",
      "min       -10.181005\n",
      "25%        -2.468518\n",
      "50%        -1.166200\n",
      "75%        -0.699064\n",
      "max         1.406415\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.35663899779319763\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 11.587419509887695\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False,  True]])\n",
      "Old tile shape: torch.Size([72, 97]), new tile shape: torch.Size([360, 485])\n",
      "Our assumed height and width of the tile values: (81216.0, 109416.0)\n",
      "71794\tPD11352a_HE-2014-12-07_11.14.57\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (37632, 47104)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([63, 79])\n",
      "The attention of the current patient looks like : count    2.689000e+03\n",
      "mean     1.583877e-04\n",
      "std      4.115727e-04\n",
      "min      9.439439e-07\n",
      "25%      1.304501e-05\n",
      "50%      2.858090e-05\n",
      "75%      1.123782e-04\n",
      "max      6.128775e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 8.557452383683994e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.006128774955868721\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([63, 79]), new tile shape: torch.Size([315, 395])\n",
      "Our assumed height and width of the tile values: (35532.0, 44556.0)\n",
      "71806\tPD7218a_I1_HE-2013-01-31_16.24.44\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"w\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (37632, 47104)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([63, 79])\n",
      "The attention of the current patient looks like : count    2689.000000\n",
      "mean       -0.414531\n",
      "std         0.555692\n",
      "min        -2.245876\n",
      "25%        -0.852498\n",
      "50%        -0.384400\n",
      "75%         0.036666\n",
      "max         1.135353\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.22396495938301086\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.3812296390533447\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([63, 79]), new tile shape: torch.Size([315, 395])\n",
      "Our assumed height and width of the tile values: (35532.0, 44556.0)\n",
      "71806\tPD7218a_I1_HE-2013-01-31_16.24.44\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"wi\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (49920, 63488)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([85, 109])\n",
      "The attention of the current patient looks like : count    6.206000e+03\n",
      "mean     1.527325e-04\n",
      "std      2.662623e-04\n",
      "min      7.192008e-08\n",
      "25%      2.523926e-06\n",
      "50%      2.361447e-05\n",
      "75%      1.859100e-04\n",
      "max      2.092756e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 0.0001023052100208588\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0020927556324750185\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([85, 109]), new tile shape: torch.Size([425, 545])\n",
      "Our assumed height and width of the tile values: (47940.0, 61476.0)\n",
      "71811\tPD4982a_FFPE-2013-01-07_18.14.32\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wi\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (49920, 63488)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([85, 109])\n",
      "The attention of the current patient looks like : count    6206.000000\n",
      "mean       -0.089647\n",
      "std         0.598914\n",
      "min        -1.912703\n",
      "25%        -0.706900\n",
      "50%         0.214858\n",
      "75%         0.394004\n",
      "max         1.111383\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.06004851311445236\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.0240862369537354\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([85, 109]), new tile shape: torch.Size([425, 545])\n",
      "Our assumed height and width of the tile values: (47940.0, 61476.0)\n",
      "71811\tPD4982a_FFPE-2013-01-07_18.14.32\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (33536, 110592)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([29, 96])\n",
      "The attention of the current patient looks like : count    349.000000\n",
      "mean       0.000652\n",
      "std        0.001125\n",
      "min        0.000002\n",
      "25%        0.000029\n",
      "50%        0.000189\n",
      "75%        0.000785\n",
      "max        0.007714\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 8.176116534741595e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0077139837667346\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False,  True,  ..., False, False, False],\n",
      "        [False, False,  True,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([29, 96]), new tile shape: torch.Size([145, 480])\n",
      "Our assumed height and width of the tile values: (32712.0, 108288.0)\n",
      "71841\tPD18031a_HE-2013-11-28_14.22.37\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (33536, 110592)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([29, 96])\n",
      "The attention of the current patient looks like : count    349.000000\n",
      "mean      -0.219761\n",
      "std        0.250898\n",
      "min       -0.828742\n",
      "25%       -0.399870\n",
      "50%       -0.248362\n",
      "75%       -0.064404\n",
      "max        0.782278\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.02754904516041279\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 1.6110200881958008\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False,  True,  ..., False, False, False],\n",
      "        [False, False,  True,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([29, 96]), new tile shape: torch.Size([145, 480])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our assumed height and width of the tile values: (32712.0, 108288.0)\n",
      "71841\tPD18031a_HE-2013-11-28_14.22.37\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (64768, 94208)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([55, 79])\n",
      "The attention of the current patient looks like : count    2.232000e+03\n",
      "mean     8.516517e-05\n",
      "std      1.752886e-04\n",
      "min      9.318292e-07\n",
      "25%      1.196250e-05\n",
      "50%      3.033092e-05\n",
      "75%      8.642666e-05\n",
      "max      2.611124e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 4.374882337288e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.002611124189570546\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([55, 79]), new tile shape: torch.Size([275, 395])\n",
      "Our assumed height and width of the tile values: (62040.0, 89112.0)\n",
      "71653\tPD9584a-1_FFPE-2012-10-29_15.39.48\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (64768, 94208)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([55, 79])\n",
      "The attention of the current patient looks like : count    2232.000000\n",
      "mean       -0.591988\n",
      "std         0.721255\n",
      "min        -2.743693\n",
      "25%        -1.080540\n",
      "50%        -0.405656\n",
      "75%        -0.051940\n",
      "max         1.070567\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.304100900888443\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.8142597675323486\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([55, 79]), new tile shape: torch.Size([275, 395])\n",
      "Our assumed height and width of the tile values: (62040.0, 89112.0)\n",
      "71653\tPD9584a-1_FFPE-2012-10-29_15.39.48\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"w\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (83712, 118784)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([74, 105])\n",
      "The attention of the current patient looks like : count    5.386000e+03\n",
      "mean     1.141679e-04\n",
      "std      2.397635e-04\n",
      "min      7.914477e-07\n",
      "25%      1.911154e-05\n",
      "50%      4.361434e-05\n",
      "75%      1.043204e-04\n",
      "max      6.704937e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 7.913880108390003e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0067049372009932995\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([74, 105]), new tile shape: torch.Size([370, 525])\n",
      "Our assumed height and width of the tile values: (83472.0, 118440.0)\n",
      "71625\tPD13420a_HE-2014-12-04_20.27.15\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (83712, 118784)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([74, 105])\n",
      "The attention of the current patient looks like : count    5386.000000\n",
      "mean       -0.106423\n",
      "std         0.200761\n",
      "min        -0.991724\n",
      "25%        -0.238830\n",
      "50%        -0.139676\n",
      "75%         0.028646\n",
      "max         0.552729\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.07376992702484131\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 1.544452428817749\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([74, 105]), new tile shape: torch.Size([370, 525])\n",
      "Our assumed height and width of the tile values: (83472.0, 118440.0)\n",
      "71625\tPD13420a_HE-2014-12-04_20.27.15\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (90112, 106496)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([79, 94])\n",
      "The attention of the current patient looks like : count    5.333000e+03\n",
      "mean     7.549602e-05\n",
      "std      3.002794e-04\n",
      "min      4.705707e-07\n",
      "25%      4.382743e-06\n",
      "50%      1.182132e-05\n",
      "75%      3.905010e-05\n",
      "max      9.765109e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 5.421764581114985e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.009765109047293663\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([79, 94]), new tile shape: torch.Size([395, 470])\n",
      "Our assumed height and width of the tile values: (89112.0, 106032.0)\n",
      "71798\tPD11385a_HE-2014-12-06_13.15.18\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (90112, 106496)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([79, 94])\n",
      "The attention of the current patient looks like : count    5333.000000\n",
      "mean       -0.799105\n",
      "std         0.880956\n",
      "min        -3.654946\n",
      "25%        -1.391516\n",
      "50%        -0.861417\n",
      "75%        -0.094106\n",
      "max         1.455827\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.5738791227340698\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 5.110773086547852\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([79, 94]), new tile shape: torch.Size([395, 470])\n",
      "Our assumed height and width of the tile values: (89112.0, 106032.0)\n",
      "71798\tPD11385a_HE-2014-12-06_13.15.18\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (77056, 110592)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([65, 94])\n",
      "The attention of the current patient looks like : count    3.124000e+03\n",
      "mean     1.639995e-04\n",
      "std      3.029513e-04\n",
      "min      3.222908e-07\n",
      "25%      1.595809e-05\n",
      "50%      4.422021e-05\n",
      "75%      1.742740e-04\n",
      "max      3.140426e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 8.385177352465689e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0031404264736920595\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([65, 94]), new tile shape: torch.Size([325, 470])\n",
      "Our assumed height and width of the tile values: (73320.0, 106032.0)\n",
      "71750\tPD8652a2_HE-2014-12-08_08.54.28\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (77056, 110592)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([65, 94])\n",
      "The attention of the current patient looks like : count    3124.000000\n",
      "mean       -0.246091\n",
      "std         0.952193\n",
      "min        -3.954521\n",
      "25%        -1.199862\n",
      "50%         0.045505\n",
      "75%         0.628053\n",
      "max         1.248622\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.12582480907440186\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 5.2031426429748535\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([65, 94]), new tile shape: torch.Size([325, 470])\n",
      "Our assumed height and width of the tile values: (73320.0, 106032.0)\n",
      "71750\tPD8652a2_HE-2014-12-08_08.54.28\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (87552, 118784)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([74, 104])\n",
      "The attention of the current patient looks like : count    619.000000\n",
      "mean       0.000683\n",
      "std        0.001512\n",
      "min        0.000001\n",
      "25%        0.000010\n",
      "50%        0.000048\n",
      "75%        0.000501\n",
      "max        0.010737\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 5.492525451700203e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.01073677372187376\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([74, 104]), new tile shape: torch.Size([370, 520])\n",
      "Our assumed height and width of the tile values: (83472.0, 117312.0)\n",
      "71823\tPD18020a_HE-2013-11-28_16.07.35\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (87552, 118784)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([74, 104])\n",
      "The attention of the current patient looks like : count    619.000000\n",
      "mean      -0.455163\n",
      "std        0.951825\n",
      "min       -5.215836\n",
      "25%       -0.835709\n",
      "50%       -0.277956\n",
      "75%        0.255861\n",
      "max        0.949061\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.03660936281085014\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 6.164896488189697\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([74, 104]), new tile shape: torch.Size([370, 520])\n",
      "Our assumed height and width of the tile values: (83472.0, 117312.0)\n",
      "71823\tPD18020a_HE-2013-11-28_16.07.35\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (54272, 69632)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([96, 123])\n",
      "The attention of the current patient looks like : count    6.755000e+03\n",
      "mean     1.247074e-04\n",
      "std      2.872611e-04\n",
      "min      2.731206e-07\n",
      "25%      6.133059e-06\n",
      "50%      1.782516e-05\n",
      "75%      8.143903e-05\n",
      "max      3.144175e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 7.134136103559285e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0031441745813935995\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ...,  True, False, False]])\n",
      "Old tile shape: torch.Size([96, 123]), new tile shape: torch.Size([480, 615])\n",
      "Our assumed height and width of the tile values: (54144.0, 69372.0)\n",
      "71615\tPD4836a - 2011-05-27 10.50.32\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"width\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (54272, 69632)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([96, 123])\n",
      "The attention of the current patient looks like : count    6755.000000\n",
      "mean       -0.369659\n",
      "std         0.715027\n",
      "min        -2.825128\n",
      "25%        -0.926796\n",
      "50%        -0.349766\n",
      "75%         0.312909\n",
      "max         1.017019\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.2114705592393875\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.842146396636963\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ...,  True, False, False]])\n",
      "Old tile shape: torch.Size([96, 123]), new tile shape: torch.Size([480, 615])\n",
      "Our assumed height and width of the tile values: (54144.0, 69372.0)\n",
      "71615\tPD4836a - 2011-05-27 10.50.32\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"width\"\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (79104, 131072)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([68, 116])\n",
      "The attention of the current patient looks like : count    5.256000e+03\n",
      "mean     1.159235e-04\n",
      "std      4.070293e-04\n",
      "min      2.595653e-07\n",
      "25%      2.768953e-06\n",
      "50%      9.401608e-06\n",
      "75%      3.791667e-05\n",
      "max      7.497331e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 7.724315946688876e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.007497331127524376\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([68, 116]), new tile shape: torch.Size([340, 580])\n",
      "Our assumed height and width of the tile values: (76704.0, 130848.0)\n",
      "71603\tPD11360a_HE-2014-12-06_22.44.51\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (79104, 131072)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([68, 116])\n",
      "The attention of the current patient looks like : count    5256.000000\n",
      "mean       -0.560926\n",
      "std         0.845473\n",
      "min        -3.068723\n",
      "25%        -1.195985\n",
      "50%        -0.705306\n",
      "75%         0.194093\n",
      "max         1.694710\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.3737610876560211\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 4.763432502746582\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([68, 116]), new tile shape: torch.Size([340, 580])\n",
      "Our assumed height and width of the tile values: (76704.0, 130848.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71603\tPD11360a_HE-2014-12-06_22.44.51\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (107776, 139264)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([93, 123])\n",
      "The attention of the current patient looks like : count    6514.000000\n",
      "mean        0.000055\n",
      "std         0.000118\n",
      "min         0.000001\n",
      "25%         0.000016\n",
      "50%         0.000030\n",
      "75%         0.000057\n",
      "max         0.004118\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 3.143702997476794e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.00411830423399806\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([93, 123]), new tile shape: torch.Size([465, 615])\n",
      "Our assumed height and width of the tile values: (104904.0, 138744.0)\n",
      "71719\tPD4267a_FFPE-2012-11-26_18.35.45\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wi\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (107776, 139264)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([93, 123])\n",
      "The attention of the current patient looks like : count    6514.000000\n",
      "mean       -0.227980\n",
      "std         0.230038\n",
      "min        -1.133575\n",
      "25%        -0.351572\n",
      "50%        -0.247898\n",
      "75%        -0.118158\n",
      "max         0.926808\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.12982429563999176\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 2.0603837966918945\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([93, 123]), new tile shape: torch.Size([465, 615])\n",
      "Our assumed height and width of the tile values: (104904.0, 138744.0)\n",
      "71719\tPD4267a_FFPE-2012-11-26_18.35.45\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (91136, 106496)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([79, 94])\n",
      "The attention of the current patient looks like : count    3.951000e+03\n",
      "mean     7.266265e-05\n",
      "std      1.104186e-04\n",
      "min      4.627696e-07\n",
      "25%      1.929441e-05\n",
      "50%      4.765276e-05\n",
      "75%      9.103263e-05\n",
      "max      2.399169e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 3.8660135032841936e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.002399169374257326\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([79, 94]), new tile shape: torch.Size([395, 470])\n",
      "Our assumed height and width of the tile values: (89112.0, 106032.0)\n",
      "71745\tPD13427a_HE-2014-12-04_17.02.15\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (91136, 106496)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([79, 94])\n",
      "The attention of the current patient looks like : count    3951.000000\n",
      "mean       -0.301488\n",
      "std         0.213147\n",
      "min        -1.728998\n",
      "25%        -0.413526\n",
      "50%        -0.254558\n",
      "75%        -0.160719\n",
      "max         0.455342\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.16040650010108948\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 2.1843395233154297\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([79, 94]), new tile shape: torch.Size([395, 470])\n",
      "Our assumed height and width of the tile values: (89112.0, 106032.0)\n",
      "71745\tPD13427a_HE-2014-12-04_17.02.15\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (89856, 86016)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([78, 76])\n",
      "The attention of the current patient looks like : count    3807.000000\n",
      "mean        0.000051\n",
      "std         0.000137\n",
      "min         0.000001\n",
      "25%         0.000008\n",
      "50%         0.000022\n",
      "75%         0.000053\n",
      "max         0.003947\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 3.251061571063474e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.003946995362639427\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False,  True,  True,  ..., False, False, False],\n",
      "        [False, False,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [False, False, False,  ...,  True,  True, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([78, 76]), new tile shape: torch.Size([390, 380])\n",
      "Our assumed height and width of the tile values: (87984.0, 85728.0)\n",
      "71832\tPD11359a_HE-2014-12-06_22.24.06\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (89856, 86016)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([78, 76])\n",
      "The attention of the current patient looks like : count    3807.000000\n",
      "mean       -0.662670\n",
      "std         0.407382\n",
      "min        -2.202362\n",
      "25%        -0.881666\n",
      "50%        -0.639989\n",
      "75%        -0.409928\n",
      "max         1.045279\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.4255709648132324\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.247640609741211\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False,  True,  True,  ..., False, False, False],\n",
      "        [False, False,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [False, False, False,  ...,  True,  True, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([78, 76]), new tile shape: torch.Size([390, 380])\n",
      "Our assumed height and width of the tile values: (87984.0, 85728.0)\n",
      "71832\tPD11359a_HE-2014-12-06_22.24.06\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (84736, 98304)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([72, 83])\n",
      "The attention of the current patient looks like : count    4.343000e+03\n",
      "mean     1.583981e-04\n",
      "std      9.358801e-04\n",
      "min      3.423920e-07\n",
      "25%      4.159552e-06\n",
      "50%      8.015338e-06\n",
      "75%      1.541381e-05\n",
      "max      1.644258e-02\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 0.00011511430056998506\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.01644258014857769\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([72, 83]), new tile shape: torch.Size([360, 415])\n",
      "Our assumed height and width of the tile values: (80640.0, 92960.0)\n",
      "71803\tPD6422a_HE\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"width\": 92960.0, \"height\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (84736, 98304)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([72, 83])\n",
      "The attention of the current patient looks like : count    4343.000000\n",
      "mean       -0.504540\n",
      "std         0.448671\n",
      "min        -2.105697\n",
      "25%        -0.758974\n",
      "50%        -0.595571\n",
      "75%        -0.288449\n",
      "max         1.176499\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.3666694462299347\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.282196521759033\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([72, 83]), new tile shape: torch.Size([360, 415])\n",
      "Our assumed height and width of the tile values: (80640.0, 92960.0)\n",
      "71803\tPD6422a_HE\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"width\": 92960.0, \"height\"\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (44032, 63488)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([78, 108])\n",
      "The attention of the current patient looks like : count    5.171000e+03\n",
      "mean     8.118437e-05\n",
      "std      2.325937e-04\n",
      "min      6.102248e-07\n",
      "25%      8.878638e-06\n",
      "50%      2.082758e-05\n",
      "75%      5.463152e-05\n",
      "max      6.230550e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 4.983433609595522e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.006230550352483988\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([78, 108]), new tile shape: torch.Size([390, 540])\n",
      "Our assumed height and width of the tile values: (43992.0, 60912.0)\n",
      "71744\tPD4069a_D_1DNAt-2011-07-15_09.49.12\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (44032, 63488)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([78, 108])\n",
      "The attention of the current patient looks like : count    5171.000000\n",
      "mean       -0.250512\n",
      "std         0.314615\n",
      "min        -1.195434\n",
      "25%        -0.509747\n",
      "50%        -0.247763\n",
      "75%        -0.001751\n",
      "max         0.870629\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.15377479791641235\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 2.066063404083252\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([78, 108]), new tile shape: torch.Size([390, 540])\n",
      "Our assumed height and width of the tile values: (43992.0, 60912.0)\n",
      "71744\tPD4069a_D_1DNAt-2011-07-15_09.49.12\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (50176, 59392)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([88, 101])\n",
      "The attention of the current patient looks like : count    5.576000e+03\n",
      "mean     1.491636e-04\n",
      "std      3.566954e-04\n",
      "min      3.523878e-07\n",
      "25%      6.311213e-06\n",
      "50%      2.183395e-05\n",
      "75%      1.154365e-04\n",
      "max      4.351060e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 9.357967792311683e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.004351060371845961\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([88, 101]), new tile shape: torch.Size([440, 505])\n",
      "Our assumed height and width of the tile values: (49632.0, 56964.0)\n",
      "71698\tPD9539a_I1_HE-2013-01-31_17.54.47\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"w\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (50176, 59392)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([88, 101])\n",
      "The attention of the current patient looks like : count    5576.000000\n",
      "mean       -0.076090\n",
      "std         0.526785\n",
      "min        -2.532712\n",
      "25%        -0.434102\n",
      "50%         0.007679\n",
      "75%         0.338686\n",
      "max         1.454863\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.04773580655455589\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.987574577331543\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([88, 101]), new tile shape: torch.Size([440, 505])\n",
      "Our assumed height and width of the tile values: (49632.0, 56964.0)\n",
      "71698\tPD9539a_I1_HE-2013-01-31_17.54.47\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"wi\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (91392, 122880)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([78, 107])\n",
      "The attention of the current patient looks like : count    5.624000e+03\n",
      "mean     8.317998e-05\n",
      "std      4.685788e-04\n",
      "min      4.128855e-07\n",
      "25%      4.752665e-06\n",
      "50%      1.280113e-05\n",
      "75%      4.024836e-05\n",
      "max      1.980706e-02\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 5.60513035452459e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.019807057455182076\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([78, 107]), new tile shape: torch.Size([390, 535])\n",
      "Our assumed height and width of the tile values: (87984.0, 120696.0)\n",
      "71666\tPD11399a_HE-2014-12-06_00.53.36\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (91392, 122880)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([78, 107])\n",
      "The attention of the current patient looks like : count    5624.000000\n",
      "mean       -0.883766\n",
      "std         0.719749\n",
      "min        -3.071373\n",
      "25%        -1.387780\n",
      "50%        -0.825962\n",
      "75%        -0.458309\n",
      "max         1.208299\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.5955305695533752\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 4.279671669006348\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([78, 107]), new tile shape: torch.Size([390, 535])\n",
      "Our assumed height and width of the tile values: (87984.0, 120696.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71666\tPD11399a_HE-2014-12-06_00.53.36\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (80896, 90112)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([66, 76])\n",
      "The attention of the current patient looks like : count    2668.000000\n",
      "mean        0.000211\n",
      "std         0.000378\n",
      "min         0.000001\n",
      "25%         0.000022\n",
      "50%         0.000070\n",
      "75%         0.000212\n",
      "max         0.005200\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 0.00011219418229302391\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0051999869756400585\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([66, 76]), new tile shape: torch.Size([330, 380])\n",
      "Our assumed height and width of the tile values: (74448.0, 85728.0)\n",
      "71766\tPD18259a-1-2014-12-11_12.59.06\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (80896, 90112)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([66, 76])\n",
      "The attention of the current patient looks like : count    2668.000000\n",
      "mean        0.031366\n",
      "std         0.470777\n",
      "min        -1.829668\n",
      "25%        -0.221027\n",
      "50%         0.141891\n",
      "75%         0.363446\n",
      "max         0.934822\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 0.016683651134371758\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 2.7644906044006348\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([66, 76]), new tile shape: torch.Size([330, 380])\n",
      "Our assumed height and width of the tile values: (74448.0, 85728.0)\n",
      "71766\tPD18259a-1-2014-12-11_12.59.06\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"width\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (54272, 65536)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([45, 53])\n",
      "The attention of the current patient looks like : count    1337.000000\n",
      "mean        0.000343\n",
      "std         0.000775\n",
      "min         0.000001\n",
      "25%         0.000014\n",
      "50%         0.000074\n",
      "75%         0.000343\n",
      "max         0.009198\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 0.0001922988158185035\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.009197947569191456\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([45, 53]), new tile shape: torch.Size([225, 265])\n",
      "Our assumed height and width of the tile values: (50760.0, 59784.0)\n",
      "71630\tPD9592a-1_FFPE-2012-10-25_02.19.38\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (54272, 65536)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([45, 53])\n",
      "The attention of the current patient looks like : count    1337.000000\n",
      "mean       -0.248764\n",
      "std         0.755402\n",
      "min        -3.099234\n",
      "25%        -0.744789\n",
      "50%        -0.111830\n",
      "75%         0.354535\n",
      "max         1.286884\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.13945409655570984\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 4.386117935180664\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([45, 53]), new tile shape: torch.Size([225, 265])\n",
      "Our assumed height and width of the tile values: (50760.0, 59784.0)\n",
      "71630\tPD9592a-1_FFPE-2012-10-25_02.19.38\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"w\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (44800, 49152)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([78, 84])\n",
      "The attention of the current patient looks like : count    1.427000e+03\n",
      "mean     1.196673e-04\n",
      "std      4.143602e-04\n",
      "min      9.290301e-07\n",
      "25%      8.330051e-06\n",
      "50%      1.808107e-05\n",
      "75%      5.334578e-05\n",
      "max      5.134508e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 2.6063065888592973e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.005134508013725281\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [False, False, False,  ...,  True, False, False]])\n",
      "Old tile shape: torch.Size([78, 84]), new tile shape: torch.Size([390, 420])\n",
      "Our assumed height and width of the tile values: (43992.0, 47376.0)\n",
      "71844\tPD5959a_A1-2-2011-05-31_16.54.15\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wi\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (44800, 49152)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([78, 84])\n",
      "The attention of the current patient looks like : count    1427.000000\n",
      "mean       -0.698159\n",
      "std         0.496811\n",
      "min        -2.439503\n",
      "25%        -1.035598\n",
      "50%        -0.608242\n",
      "75%        -0.369470\n",
      "max         0.844513\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.15205641090869904\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.2840161323547363\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [False, False, False,  ...,  True, False, False],\n",
      "        [False, False, False,  ...,  True, False, False]])\n",
      "Old tile shape: torch.Size([78, 84]), new tile shape: torch.Size([390, 420])\n",
      "Our assumed height and width of the tile values: (43992.0, 47376.0)\n",
      "71844\tPD5959a_A1-2-2011-05-31_16.54.15\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (60672, 77824)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([51, 63])\n",
      "The attention of the current patient looks like : count    1612.000000\n",
      "mean        0.000203\n",
      "std         0.000307\n",
      "min         0.000001\n",
      "25%         0.000028\n",
      "50%         0.000097\n",
      "75%         0.000250\n",
      "max         0.005191\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 0.00010205843136645854\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.005190874915570021\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([51, 63]), new tile shape: torch.Size([255, 315])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our assumed height and width of the tile values: (57528.0, 71064.0)\n",
      "71853\tPD9599a-1_FFPE-2012-10-29_11.55.15\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (60672, 77824)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([51, 63])\n",
      "The attention of the current patient looks like : count    1612.000000\n",
      "mean       -0.194558\n",
      "std         0.869458\n",
      "min        -3.235076\n",
      "25%        -0.464620\n",
      "50%         0.100558\n",
      "75%         0.366541\n",
      "max         1.207025\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.09761210530996323\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 4.44210147857666\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([51, 63]), new tile shape: torch.Size([255, 315])\n",
      "Our assumed height and width of the tile values: (57528.0, 71064.0)\n",
      "71853\tPD9599a-1_FFPE-2012-10-29_11.55.15\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"w\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (46080, 57344)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([38, 46])\n",
      "The attention of the current patient looks like : count    7.540000e+02\n",
      "mean     1.394390e-04\n",
      "std      2.236914e-04\n",
      "min      8.431875e-07\n",
      "25%      1.683233e-05\n",
      "50%      5.302267e-05\n",
      "75%      1.681258e-04\n",
      "max      1.888505e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 6.014704194967635e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0018885047174990177\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([38, 46]), new tile shape: torch.Size([190, 230])\n",
      "Our assumed height and width of the tile values: (42864.0, 51888.0)\n",
      "71703\tPD9593a-1_FFPE-2012-10-25_03.06.46\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (46080, 57344)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([38, 46])\n",
      "The attention of the current patient looks like : count    754.000000\n",
      "mean      -0.990036\n",
      "std        1.312048\n",
      "min       -6.417823\n",
      "25%       -1.913916\n",
      "50%       -0.553910\n",
      "75%        0.100254\n",
      "max        0.851120\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.42705202102661133\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 7.2689433097839355\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([38, 46]), new tile shape: torch.Size([190, 230])\n",
      "Our assumed height and width of the tile values: (42864.0, 51888.0)\n",
      "71703\tPD9593a-1_FFPE-2012-10-25_03.06.46\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"w\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (36352, 45056)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([30, 37])\n",
      "The attention of the current patient looks like : count    618.000000\n",
      "mean       0.000048\n",
      "std        0.000100\n",
      "min        0.000001\n",
      "25%        0.000008\n",
      "50%        0.000018\n",
      "75%        0.000047\n",
      "max        0.000985\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 2.6717407308751717e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0009851669892668724\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([30, 37]), new tile shape: torch.Size([150, 185])\n",
      "Our assumed height and width of the tile values: (33840.0, 41736.0)\n",
      "71758\tPD8620a-1_FFPE-2012-09-24_14.50.50\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (36352, 45056)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([30, 37])\n",
      "The attention of the current patient looks like : count    618.000000\n",
      "mean      -2.133642\n",
      "std        0.973909\n",
      "min       -7.032815\n",
      "25%       -2.617687\n",
      "50%       -2.047569\n",
      "75%       -1.489502\n",
      "max        0.264669\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -1.1879197359085083\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 7.297484397888184\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([30, 37]), new tile shape: torch.Size([150, 185])\n",
      "Our assumed height and width of the tile values: (33840.0, 41736.0)\n",
      "71758\tPD8620a-1_FFPE-2012-09-24_14.50.50\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"w\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (45312, 63488)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([76, 109])\n",
      "The attention of the current patient looks like : count    6.365000e+03\n",
      "mean     7.374865e-05\n",
      "std      3.612227e-04\n",
      "min      8.050198e-07\n",
      "25%      4.955186e-06\n",
      "50%      8.066256e-06\n",
      "75%      1.677396e-05\n",
      "max      6.844291e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 5.6664677686057985e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.006844290532171726\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([76, 109]), new tile shape: torch.Size([380, 545])\n",
      "Our assumed height and width of the tile values: (42864.0, 61476.0)\n",
      "71606\tPD8978a_FFPE_H_E-2013-01-07_12.47.53\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\",\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (45312, 63488)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([76, 109])\n",
      "The attention of the current patient looks like : count    6365.000000\n",
      "mean       -1.206461\n",
      "std         0.722555\n",
      "min        -3.222307\n",
      "25%        -1.746614\n",
      "50%        -1.285338\n",
      "75%        -0.789137\n",
      "max         1.118995\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.9269824028015137\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 4.341302394866943\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([76, 109]), new tile shape: torch.Size([380, 545])\n",
      "Our assumed height and width of the tile values: (42864.0, 61476.0)\n",
      "71606\tPD8978a_FFPE_H_E-2013-01-07_12.47.53\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (103680, 114688)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([91, 99])\n",
      "The attention of the current patient looks like : count    5.609000e+03\n",
      "mean     8.500372e-05\n",
      "std      5.091927e-04\n",
      "min      5.957845e-07\n",
      "25%      6.753776e-06\n",
      "50%      1.415062e-05\n",
      "75%      3.473547e-05\n",
      "max      1.678061e-02\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 5.292328933137469e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.016780607402324677\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([91, 99]), new tile shape: torch.Size([455, 495])\n",
      "Our assumed height and width of the tile values: (102648.0, 111672.0)\n",
      "71804\tPD14441a_FFPE-T_HE-2013-11-06_16.45.24\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (103680, 114688)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([91, 99])\n",
      "The attention of the current patient looks like : count    5609.000000\n",
      "mean       -0.396760\n",
      "std         0.584661\n",
      "min        -3.032812\n",
      "25%        -0.808012\n",
      "50%        -0.361807\n",
      "75%         0.041357\n",
      "max         1.459008\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.24702277779579163\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 4.491819381713867\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([91, 99]), new tile shape: torch.Size([455, 495])\n",
      "Our assumed height and width of the tile values: (102648.0, 111672.0)\n",
      "71804\tPD14441a_FFPE-T_HE-2013-11-06_16.45.24\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\"\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (51200, 61440)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([89, 107])\n",
      "The attention of the current patient looks like : count    4.933000e+03\n",
      "mean     8.049236e-05\n",
      "std      3.057953e-04\n",
      "min      3.612191e-07\n",
      "25%      4.522599e-06\n",
      "50%      1.655397e-05\n",
      "75%      3.433121e-05\n",
      "max      6.731980e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 4.169576641288586e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.006731980014592409\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([89, 107]), new tile shape: torch.Size([445, 535])\n",
      "Our assumed height and width of the tile values: (50196.0, 60348.0)\n",
      "71613\tPD8828a_I23_HE-2013-01-31_14.48.36\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (51200, 61440)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([89, 107])\n",
      "The attention of the current patient looks like : count    4933.000000\n",
      "mean       -1.022628\n",
      "std         0.838191\n",
      "min        -5.428931\n",
      "25%        -1.323676\n",
      "50%        -0.987636\n",
      "75%        -0.765285\n",
      "max         1.213820\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.5297302603721619\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 6.6427507400512695\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([89, 107]), new tile shape: torch.Size([445, 535])\n",
      "Our assumed height and width of the tile values: (50196.0, 60348.0)\n",
      "71613\tPD8828a_I23_HE-2013-01-31_14.48.36\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"w\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (84992, 135168)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([75, 119])\n",
      "The attention of the current patient looks like : count    4.341000e+03\n",
      "mean     2.412550e-05\n",
      "std      1.037749e-04\n",
      "min      3.923638e-07\n",
      "25%      2.133351e-06\n",
      "50%      5.727668e-06\n",
      "75%      1.953893e-05\n",
      "max      2.781517e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 1.1734317013178952e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0027815173380076885\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False,  True],\n",
      "        [False, False, False,  ..., False,  True,  True]])\n",
      "Old tile shape: torch.Size([75, 119]), new tile shape: torch.Size([375, 595])\n",
      "Our assumed height and width of the tile values: (84600.0, 134232.0)\n",
      "71818\tPD10010a_HE-2014-12-07_14.37.01\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (84992, 135168)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([75, 119])\n",
      "The attention of the current patient looks like : count    4341.000000\n",
      "mean       -1.542817\n",
      "std         0.895133\n",
      "min        -4.973800\n",
      "25%        -2.029036\n",
      "50%        -1.365639\n",
      "75%        -0.960200\n",
      "max         0.902009\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.7504053711891174\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 5.875809192657471\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False,  True],\n",
      "        [False, False, False,  ..., False,  True,  True]])\n",
      "Old tile shape: torch.Size([75, 119]), new tile shape: torch.Size([375, 595])\n",
      "Our assumed height and width of the tile values: (84600.0, 134232.0)\n",
      "71818\tPD10010a_HE-2014-12-07_14.37.01\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (55552, 69632)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([49, 57])\n",
      "The attention of the current patient looks like : count    1068.000000\n",
      "mean        0.000075\n",
      "std         0.000209\n",
      "min         0.000001\n",
      "25%         0.000010\n",
      "50%         0.000022\n",
      "75%         0.000059\n",
      "max         0.002802\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 2.8558739359141327e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.00280228303745389\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([49, 57]), new tile shape: torch.Size([245, 285])\n",
      "Our assumed height and width of the tile values: (55272.0, 64296.0)\n",
      "71672\tPD9578a-1_FFPE-2012-10-25_01.43.19\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (55552, 69632)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([49, 57])\n",
      "The attention of the current patient looks like : count    1068.000000\n",
      "mean       -1.172444\n",
      "std         0.769042\n",
      "min        -4.672063\n",
      "25%        -1.501745\n",
      "50%        -1.036454\n",
      "75%        -0.724156\n",
      "max         1.183666\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.44832444190979004\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 5.855729579925537\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([49, 57]), new tile shape: torch.Size([245, 285])\n",
      "Our assumed height and width of the tile values: (55272.0, 64296.0)\n",
      "71672\tPD9578a-1_FFPE-2012-10-25_01.43.19\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"w\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (82944, 98304)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([71, 87])\n",
      "The attention of the current patient looks like : count    3.847000e+03\n",
      "mean     1.376266e-04\n",
      "std      4.527314e-04\n",
      "min      2.554159e-07\n",
      "25%      3.417916e-06\n",
      "50%      1.235340e-05\n",
      "75%      6.271685e-05\n",
      "max      9.228827e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 8.571307989768684e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.009228826500475407\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([71, 87]), new tile shape: torch.Size([355, 435])\n",
      "Our assumed height and width of the tile values: (80088.0, 98136.0)\n",
      "71751\tPD11372a_ER-2014-12-07_04.18.02\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (82944, 98304)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([71, 87])\n",
      "The attention of the current patient looks like : count    3847.000000\n",
      "mean       -0.794725\n",
      "std         1.117445\n",
      "min        -4.000281\n",
      "25%        -1.648854\n",
      "50%        -0.960965\n",
      "75%         0.297621\n",
      "max         1.259308\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.4949498176574707\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 5.259588241577148\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([71, 87]), new tile shape: torch.Size([355, 435])\n",
      "Our assumed height and width of the tile values: (80088.0, 98136.0)\n",
      "71751\tPD11372a_ER-2014-12-07_04.18.02\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (81664, 90112)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([71, 78])\n",
      "The attention of the current patient looks like : count    2850.000000\n",
      "mean        0.000125\n",
      "std         0.000330\n",
      "min         0.000001\n",
      "25%         0.000021\n",
      "50%         0.000041\n",
      "75%         0.000092\n",
      "max         0.004951\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 6.419059354811907e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.004951411858201027\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([71, 78]), new tile shape: torch.Size([355, 390])\n",
      "Our assumed height and width of the tile values: (80088.0, 87984.0)\n",
      "71736\tPD13416a_HE-2014-12-04_22.51.33\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (81664, 90112)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([71, 78])\n",
      "The attention of the current patient looks like : count    2850.000000\n",
      "mean       -0.324520\n",
      "std         0.449279\n",
      "min        -1.931525\n",
      "25%        -0.622243\n",
      "50%        -0.394376\n",
      "75%        -0.076055\n",
      "max         1.131079\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.16700634360313416\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.0626039505004883\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([71, 78]), new tile shape: torch.Size([355, 390])\n",
      "Our assumed height and width of the tile values: (80088.0, 87984.0)\n",
      "71736\tPD13416a_HE-2014-12-04_22.51.33\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (92672, 106496)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([75, 87])\n",
      "The attention of the current patient looks like : count    3.875000e+03\n",
      "mean     1.833583e-04\n",
      "std      4.259666e-04\n",
      "min      2.436971e-07\n",
      "25%      4.046519e-06\n",
      "50%      1.826352e-05\n",
      "75%      1.621206e-04\n",
      "max      5.563651e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 0.00010889091936405748\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.005563650745898485\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([75, 87]), new tile shape: torch.Size([375, 435])\n",
      "Our assumed height and width of the tile values: (84600.0, 98136.0)\n",
      "71657\tPD14437a_FFPE-T_HE-2013-11-06_20.24.39\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (92672, 106496)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([75, 87])\n",
      "The attention of the current patient looks like : count    3875.000000\n",
      "mean       -0.020041\n",
      "std         0.626148\n",
      "min        -1.948524\n",
      "25%        -0.529242\n",
      "50%         0.130868\n",
      "75%         0.492701\n",
      "max         1.213314\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.011901972815394402\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.1618380546569824\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([75, 87]), new tile shape: torch.Size([375, 435])\n",
      "Our assumed height and width of the tile values: (84600.0, 98136.0)\n",
      "71657\tPD14437a_FFPE-T_HE-2013-11-06_20.24.39\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (52736, 69632)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([93, 123])\n",
      "The attention of the current patient looks like : count    6.692000e+03\n",
      "mean     1.004019e-04\n",
      "std      3.849231e-04\n",
      "min      3.384709e-07\n",
      "25%      3.834638e-06\n",
      "50%      9.409779e-06\n",
      "75%      2.776913e-05\n",
      "max      7.342031e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 5.87367539992556e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.007342030759900808\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ...,  True,  True,  True]])\n",
      "Old tile shape: torch.Size([93, 123]), new tile shape: torch.Size([465, 615])\n",
      "Our assumed height and width of the tile values: (52452.0, 69372.0)\n",
      "71700\tPD7240a_HE-2013-01-08_20.41.09\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (52736, 69632)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([93, 123])\n",
      "The attention of the current patient looks like : count    6692.000000\n",
      "mean       -0.526613\n",
      "std         0.617588\n",
      "min        -3.279731\n",
      "25%        -0.898570\n",
      "50%        -0.552608\n",
      "75%        -0.175471\n",
      "max         1.303654\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.3080769181251526\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 4.583385467529297\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ...,  True,  True,  True]])\n",
      "Old tile shape: torch.Size([93, 123]), new tile shape: torch.Size([465, 615])\n",
      "Our assumed height and width of the tile values: (52452.0, 69372.0)\n",
      "71700\tPD7240a_HE-2013-01-08_20.41.09\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"width\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (78848, 151552)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([66, 130])\n",
      "The attention of the current patient looks like : count    1497.000000\n",
      "mean        0.000072\n",
      "std         0.000183\n",
      "min         0.000002\n",
      "25%         0.000010\n",
      "50%         0.000020\n",
      "75%         0.000056\n",
      "max         0.003527\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 1.2545231584226713e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0035270487423986197\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([66, 130]), new tile shape: torch.Size([330, 650])\n",
      "Our assumed height and width of the tile values: (74448.0, 146640.0)\n",
      "71654\tPD18022a_HE-2013-11-28_11.55.53\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"wid\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (78848, 151552)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([66, 130])\n",
      "The attention of the current patient looks like : count    1497.000000\n",
      "mean       -1.008458\n",
      "std         0.445215\n",
      "min        -3.012739\n",
      "25%        -1.288825\n",
      "50%        -0.977717\n",
      "75%        -0.708413\n",
      "max         0.297854\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.175951287150383\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.310593605041504\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([66, 130]), new tile shape: torch.Size([330, 650])\n",
      "Our assumed height and width of the tile values: (74448.0, 146640.0)\n",
      "71654\tPD18022a_HE-2013-11-28_11.55.53\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"widt\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (99072, 122880)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([87, 107])\n",
      "The attention of the current patient looks like : count    5.949000e+03\n",
      "mean     1.577955e-04\n",
      "std      2.956405e-04\n",
      "min      1.020012e-07\n",
      "25%      1.387363e-06\n",
      "50%      1.119202e-05\n",
      "75%      1.786896e-04\n",
      "max      2.628127e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 0.00010084063251269981\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.002628127345815301\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([87, 107]), new tile shape: torch.Size([435, 535])\n",
      "Our assumed height and width of the tile values: (98136.0, 120696.0)\n",
      "71597\tPD6406a_10_00_1\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"width\": 120696.0, \"\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (99072, 122880)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([87, 107])\n",
      "The attention of the current patient looks like : count    5949.000000\n",
      "mean       -0.129936\n",
      "std         0.523035\n",
      "min        -1.618190\n",
      "25%        -0.578200\n",
      "50%         0.074242\n",
      "75%         0.309261\n",
      "max         0.833082\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.08303697407245636\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 2.4512712955474854\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([87, 107]), new tile shape: torch.Size([435, 535])\n",
      "Our assumed height and width of the tile values: (98136.0, 120696.0)\n",
      "71597\tPD6406a_10_00_1\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"width\": 120696.0, \"h\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (90624, 143360)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([80, 127])\n",
      "The attention of the current patient looks like : count    6.551000e+03\n",
      "mean     1.385853e-04\n",
      "std      3.734644e-04\n",
      "min      1.389878e-07\n",
      "25%      1.658777e-06\n",
      "50%      4.291830e-06\n",
      "75%      5.314849e-05\n",
      "max      5.620660e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 8.935751975513995e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0056206597946584225\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([80, 127]), new tile shape: torch.Size([400, 635])\n",
      "Our assumed height and width of the tile values: (90240.0, 143256.0)\n",
      "71800\tPD4958a-2013-05-16_10.14.43\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"width\":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (90624, 143360)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([80, 127])\n",
      "The attention of the current patient looks like : count    6551.000000\n",
      "mean       -0.131310\n",
      "std         0.469295\n",
      "min        -2.407677\n",
      "25%        -0.479566\n",
      "50%        -0.068183\n",
      "75%         0.269252\n",
      "max         0.739991\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.08466646820306778\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 3.147667646408081\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([80, 127]), new tile shape: torch.Size([400, 635])\n",
      "Our assumed height and width of the tile values: (90240.0, 143256.0)\n",
      "71800\tPD4958a-2013-05-16_10.14.43\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"width\": \n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (28160, 73728)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([49, 129])\n",
      "The attention of the current patient looks like : count    2.240000e+03\n",
      "mean     4.783079e-05\n",
      "std      1.801572e-04\n",
      "min      7.751992e-07\n",
      "25%      6.062851e-06\n",
      "50%      1.352987e-05\n",
      "75%      3.411917e-05\n",
      "max      6.697463e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 1.6950003555393778e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.00669746333733201\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([49, 129]), new tile shape: torch.Size([245, 645])\n",
      "Our assumed height and width of the tile values: (27636.0, 72756.0)\n",
      "71805\tPD8612a-2011-05-31_14.42.33\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"width\":\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (28160, 73728)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([49, 129])\n",
      "The attention of the current patient looks like : count    2240.000000\n",
      "mean       -0.838160\n",
      "std         0.680292\n",
      "min        -4.219710\n",
      "25%        -1.185306\n",
      "50%        -0.761840\n",
      "75%        -0.384345\n",
      "max         0.923184\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.2970222234725952\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 5.142894744873047\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([49, 129]), new tile shape: torch.Size([245, 645])\n",
      "Our assumed height and width of the tile values: (27636.0, 72756.0)\n",
      "71805\tPD8612a-2011-05-31_14.42.33\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"width\": \n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (51712, 65536)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([87, 115])\n",
      "The attention of the current patient looks like : count    6.376000e+03\n",
      "mean     3.784664e-05\n",
      "std      9.653478e-05\n",
      "min      7.971651e-07\n",
      "25%      1.020210e-05\n",
      "50%      2.031798e-05\n",
      "75%      3.667864e-05\n",
      "max      2.970522e-03\n",
      "Name: attention, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like 2.411895547993481e-05\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 0.0029705222696065903\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False,  True,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([87, 115]), new tile shape: torch.Size([435, 575])\n",
      "Our assumed height and width of the tile values: (49068.0, 64860.0)\n",
      "71791\tPD7221a_I6_HE-2013-01-31_15.57.13\tyschirris@gmail.com\tyoni_heatmap_attention_hrd\t[{\"type\": \"heatmap\", \"w\n",
      "In upload results...\n",
      "In ceeate custom heatmap annotation...\n",
      "Actual height and width of image: (51712, 65536)\n",
      "In get_attention...\n",
      "Shape of the tiled WSI: torch.Size([87, 115])\n",
      "The attention of the current patient looks like : count    6376.000000\n",
      "mean       -0.413061\n",
      "std         0.209302\n",
      "min        -1.461250\n",
      "25%        -0.520784\n",
      "50%        -0.401814\n",
      "75%        -0.308252\n",
      "max         0.878233\n",
      "Name: attention_gradients, dtype: float64\n",
      "After setting values in the tile, value_tiles looks like -0.26323583722114563\n",
      "Rescaling values so that the max attention is set to 255\n",
      "max attention: 2.339482307434082\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False,  True,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "Old tile shape: torch.Size([87, 115]), new tile shape: torch.Size([435, 575])\n",
      "Our assumed height and width of the tile values: (49068.0, 64860.0)\n",
      "71791\tPD7221a_I6_HE-2013-01-31_15.57.13\tyschirris@gmail.com\tyoni_heatmap_gradient_hrd\t[{\"type\": \"heatmap\", \"wi\n"
     ]
    }
   ],
   "source": [
    "root = \"/home/yonis/SimCLR-1/\"\n",
    "output = \"logs/eval/1342\" ## BASIS, median HRD prediction, 85% ROCUAC\n",
    "attention_output_file = \"/home/yonis/SimCLR-1/logs/eval/1342/attention_output_epoch_21_2020-10-09-16-24-40.csv\" # \n",
    "\n",
    "\n",
    "# Could use https://rhpc.nki.nl/slidescore/docs/api.html#get-images\n",
    "\n",
    "# ['PD7217a', 'PD11366a', 'PD13422a', 'PD11352a', 'PD7218a',\n",
    "#        'PD4982a', 'PD18031a', 'PD9584a', 'PD13420a', 'PD11385a',\n",
    "#        'PD8652a', 'PD18020a', 'PD4836a', 'PD11360a', 'PD4267a',\n",
    "#        'PD13427a', 'PD11359a', 'PD6422a', 'PD4069a', 'PD9539a',\n",
    "#        'PD11399a', 'PD18259a', 'PD9592a', 'PD5959a', 'PD9599a', 'PD9593a',\n",
    "#        'PD8620a', 'PD8978a', 'PD14441a', 'PD8828a', 'PD10010a', 'PD9578a',\n",
    "#        'PD11372a', 'PD13416a', 'PD14437a', 'PD7240a', 'PD18022a',\n",
    "#        'PD6406a', 'PD4958a', 'PD8612a', 'PD7221a'].forEach(st => [...document.querySelectorAll(\"a\")]\n",
    "#    .filter(a => a.textContent.includes(st))\n",
    "#    .forEach(a => console.log(\"[\" + st + \",\" + a.textContent + \",\" + a.href.split(\"?\")[1].split(\"=\")[1].split(\"&\")[0] + \"]\")))\n",
    "slidescore_list = [\n",
    "[\"PD7217a\", 'PD7217a_I9_HE-2013-01-31_17.25.04',71717] \n",
    ",[\"PD11366a\", \"PD11366a_HE-2014-12-07_02.09.37\",71762] \n",
    ",[\"PD13422a\", \"PD13422a_HE-2014-12-04_19.12.33\",71635] \n",
    ",[\"PD11352a\", \"PD11352a_HE-2014-12-07_11.14.57\",71794] \n",
    ",[\"PD7218a\", \"PD7218a_I1_HE-2013-01-31_16.24.44\",71806]\n",
    ",[\"PD4982a\", \"PD4982a_FFPE-2013-01-07_18.14.32\",71811] \n",
    ",[\"PD18031a\", \"PD18031a_HE-2013-11-28_14.22.37\",71841] \n",
    ",[\"PD9584a\", \"PD9584a-1_FFPE-2012-10-29_15.39.48\",71653]\n",
    ",[\"PD13420a\", \"PD13420a_HE-2014-12-04_20.27.15\",71625] \n",
    ",[\"PD11385a\", \"PD11385a_HE-2014-12-06_13.15.18\",71798] \n",
    ",[\"PD8652a\", \"PD8652a2_HE-2014-12-08_08.54.28\",71750] \n",
    ",[\"PD18020a\", \"PD18020a_HE-2013-11-28_16.07.35\",71823] \n",
    ",[\"PD4836a\", \"PD4836a - 2011-05-27 10.50.32\",71615] \n",
    ",[\"PD11360a\", \"PD11360a_HE-2014-12-06_22.44.51\",71603] \n",
    ",[\"PD4267a\", \"PD4267a_FFPE-2012-11-26_18.35.45\",71719] \n",
    ",[\"PD13427a\", \"PD13427a_HE-2014-12-04_17.02.15\",71745] \n",
    ",[\"PD11359a\", \"PD11359a_HE-2014-12-06_22.24.06\",71832] \n",
    ",[\"PD6422a\", \"PD6422a_HE\",71803] \n",
    ",[\"PD4069a\", \"PD4069a_D_1DNAt-2011-07-15_09.49.12\",71744] \n",
    ",[\"PD9539a\", \"PD9539a_I1_HE-2013-01-31_17.54.47\",71698] \n",
    ",[\"PD11399a\", \"PD11399a_HE-2014-12-06_00.53.36\",71666] \n",
    ",[\"PD18259a\", \"PD18259a-1-2014-12-11_12.59.06\",71766] \n",
    ",[\"PD9592a\", \"PD9592a-1_FFPE-2012-10-25_02.19.38\",71630] \n",
    ",[\"PD5959a\", \"PD5959a_A1-2-2011-05-31_16.54.15\",71844] \n",
    ",[\"PD9599a\", \"PD9599a-1_FFPE-2012-10-29_11.55.15\",71853] \n",
    ",[\"PD9593a\", \"PD9593a-1_FFPE-2012-10-25_03.06.46\",71703] \n",
    ",[\"PD8620a\", \"PD8620a-1_FFPE-2012-09-24_14.50.50\",71758] \n",
    ",[\"PD8978a\", \"PD8978a_FFPE_H_E-2013-01-07_12.47.53\",71606]\n",
    ",[\"PD14441a\", \"PD14441a_FFPE-T_HE-2013-11-06_16.45.24\",71804] \n",
    ",[\"PD8828a\", \"PD8828a_I23_HE-2013-01-31_14.48.36\",71613] \n",
    ",[\"PD10010a\", \"PD10010a_HE-2014-12-07_14.37.01\",71818] \n",
    ",[\"PD9578a\", \"PD9578a-1_FFPE-2012-10-25_01.43.19\",71672]\n",
    ",[\"PD11372a\", \"PD11372a_ER-2014-12-07_04.18.02\",71751]\n",
    ",[\"PD13416a\", \"PD13416a_HE-2014-12-04_22.51.33\",71736]\n",
    ",[\"PD14437a\", \"PD14437a_FFPE-T_HE-2013-11-06_20.24.39\",71657]\n",
    ",[\"PD7240a\", \"PD7240a_HE-2013-01-08_20.41.09\",71700]\n",
    ",[\"PD18022a\", \"PD18022a_HE-2013-11-28_11.55.53\",71654]\n",
    ",[\"PD6406a\", \"PD6406a_10_00_1\",71597] \n",
    ",[\"PD4958a\", \"PD4958a-2013-05-16_10.14.43\",71800] \n",
    ",[\"PD8612a\", \"PD8612a-2011-05-31_14.42.33\",71805] \n",
    ",[\"PD7221a\", \"PD7221a_I6_HE-2013-01-31_15.57.13\",71791]]\n",
    "\n",
    "cases = ['PD7217a', 'PD11366a', 'PD13422a', 'PD11352a', 'PD7218a',\n",
    "       'PD4982a', 'PD18031a', 'PD9584a', 'PD13420a', 'PD11385a',\n",
    "       'PD8652a', 'PD18020a', 'PD4836a', 'PD11360a', 'PD4267a',\n",
    "       'PD13427a', 'PD11359a', 'PD6422a', 'PD4069a', 'PD9539a',\n",
    "       'PD11399a', 'PD18259a', 'PD9592a', 'PD5959a', 'PD9599a', 'PD9593a',\n",
    "       'PD8620a', 'PD8978a', 'PD14441a', 'PD8828a', 'PD10010a', 'PD9578a',\n",
    "       'PD11372a', 'PD13416a', 'PD14437a', 'PD7240a', 'PD18022a',\n",
    "       'PD6406a', 'PD4958a', 'PD8612a', 'PD7221a']\n",
    "dot_ids = ['YID227', 'YID250', 'YID200', 'YID154', 'YID072', 'YID016',\n",
    "       'YID249', 'YID013', 'YID225', 'YID119', 'YID178', 'YID038',\n",
    "       'YID113', 'YID216', 'YID023', 'YID197', 'YID028', 'YID228',\n",
    "       'YID140', 'YID183', 'YID059', 'YID202', 'YID062', 'YID194',\n",
    "       'YID109', 'YID210', 'YID095', 'YID175', 'YID030', 'YID224',\n",
    "       'YID041', 'YID161', 'YID171', 'YID042', 'YID073', 'YID189',\n",
    "       'YID209', 'YID061', 'YID176', 'YID081', 'YID236']\n",
    "\n",
    "wsi_paths = []\n",
    "tilejson_paths = []\n",
    "\n",
    "for case, dot_id in zip(cases, dot_ids):\n",
    "    wsi_paths.append(f\"/project/schirris/tiled_data_large/case-{case}/pid_{dot_id}_tile_grid_extractor_585.pt\")\n",
    "    tilejson_paths.append(f\"/project/schirris/tiled_data_large/case-{case}/{dot_id}/json/tile0.json\")\n",
    "\n",
    "\n",
    "for ([current_case, filename, slidescore_im_id], wsi_path, tilejson_path) in zip(slidescore_list, wsi_paths, tilejson_paths):\n",
    "    upload_results(current_case, slidescore_im_id, attention_output_file, wsi_path, 'attention', tilejson_path)\n",
    "    upload_results(current_case, slidescore_im_id, attention_output_file, wsi_path, 'attention_gradients', tilejson_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/yonis/SimCLR-1/logs/eval/1342/attention_output_epoch_21_2020-10-09-16-24-40.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tile_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>attention</th>\n",
       "      <th>attention_gradients</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>pd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>data</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.096035</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>data</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.096035</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>data</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.096035</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>data</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.096035</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>data</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.096035</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>tensor(nan)</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    tile_name patient_id  attention  attention_gradients  \\\n",
       "0           0  tensor(nan)       data   0.000117             0.096035   \n",
       "1           1  tensor(nan)       data   0.000117             0.096035   \n",
       "2           2  tensor(nan)       data   0.000117             0.096035   \n",
       "3           3  tensor(nan)       data   0.000117             0.096035   \n",
       "4           4  tensor(nan)       data   0.000117             0.096035   \n",
       "\n",
       "             x            y pd  \n",
       "0  tensor(nan)  tensor(nan)  a  \n",
       "1  tensor(nan)  tensor(nan)  a  \n",
       "2  tensor(nan)  tensor(nan)  a  \n",
       "3  tensor(nan)  tensor(nan)  a  \n",
       "4  tensor(nan)  tensor(nan)  a  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['attention'].describe()\n",
    "df['pd'] = df.apply(lambda x: x['tile_name'].split('/')[4] if x['tile_name'] != 'tensor(nan)' else 'a', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'case-PD10010a', 'case-PD11352a', 'case-PD11359a',\n",
       "       'case-PD11360a', 'case-PD11366a', 'case-PD11372a', 'case-PD11385a',\n",
       "       'case-PD11399a', 'case-PD13416a', 'case-PD13420a', 'case-PD13422a',\n",
       "       'case-PD13427a', 'case-PD14437a', 'case-PD14441a', 'case-PD18020a',\n",
       "       'case-PD18022a', 'case-PD18031a', 'case-PD18259a', 'case-PD4069a',\n",
       "       'case-PD4267a', 'case-PD4836a', 'case-PD4958a', 'case-PD4982a',\n",
       "       'case-PD5959a', 'case-PD6406a', 'case-PD6422a', 'case-PD7217a',\n",
       "       'case-PD7218a', 'case-PD7221a', 'case-PD7240a', 'case-PD8612a',\n",
       "       'case-PD8620a', 'case-PD8652a', 'case-PD8828a', 'case-PD8978a',\n",
       "       'case-PD9539a', 'case-PD9578a', 'case-PD9584a', 'case-PD9592a',\n",
       "       'case-PD9593a', 'case-PD9599a'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
