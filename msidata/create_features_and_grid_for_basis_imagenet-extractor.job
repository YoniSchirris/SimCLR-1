#!/bin/bash

#SBATCH --job-name=create_grid
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=4
#SBATCH --partition=gpu_shared
#SBATCH --gres=gpu:1
#SBATCH --ntasks=1
#SBATCH --time=10:0:0

module purge
module load 2019

module load Anaconda3
module load CUDA/10.0.130
module load cuDNN/7.6.3-CUDA-10.0.130
export LD_LIBRARY_PATH=/hpc/eb/Debian9/cuDNN/7.6.3-CUDA-10.0.130/lib64:$LD_LIBRARY_PATH

CONDA_PREFIX=$(conda info --base)
source $CONDA_PREFIX/etc/profile.d/conda.sh
conda deactivate
conda activate thesisp375_clone # has pytorch 1.6 instead of 1.4
cd ..
#srun python -m msidata.save_feature_vectors with config_file=./config/config-create-features-and-grid-brca-dx.yaml batch_size=1024 workers=0 path_to_msi_data=/home/yonis/histogenomics-msc-2019/yoni-code/MsiPrediction/metadata/tcga/brca_dx/data_tcga_brca_dxwith_ddr_labels_and_splits_dropna.csv use_precomputed_features=True use_precomputed_features_id=585  # compute and save all feature vectors. aggregate all into large feature grids

label_file=/project/schirris/basisscripts/step_3/data_basis_brca_with_labels_and_splits.csv

#python -m msidata.save_feature_vectors with config_file=./config/config-create-features-and-grid-basis.yaml workers=0 use_precomputed_features=True use_precomputed_features_id=585

python -m msidata.save_feature_vectors with config_file=./config/config-create-features-and-grid-basis.yaml workers=6 reload_classifier=False logistic_extractor=imagenet-shufflenetv2_x1_0 reload_model=False
