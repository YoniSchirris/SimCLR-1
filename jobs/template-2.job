#!/bin/bash

#SBATCH --job-name=template_script
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=12
#SBATCH --partition=gpu_shared
#SBATCH --ntasks=1
#SBATCH --gres=gpu:1
#SBATCH --time=1-0:00:00

module purge
module load 2019

module load Anaconda3
module load CUDA/10.0.130
module load cuDNN/7.6.3-CUDA-10.0.130
export LD_LIBRARY_PATH=/hpc/eb/Debian9/cuDNN/7.6.3-CUDA-10.0.130/lib64:$LD_LIBRARY_PATH

CONDA_PREFIX=$(conda info --base)
source $CONDA_PREFIX/etc/profile.d/conda.sh
conda activate ENVIRONMENT

#VARIABLES
ORIGINAL_DATA_PATH=PATH/TO/DIR
ORIGINAL_DATA_PATH_TEST=PATH/TO/TEST/DIR
TMP_PARENT_DIR_FOR_DATA=SOME/DIR/NAME

cd ..
echo "starting to copy to scratch..."
date
mkdir -p "$TMPDIR"/$TMP_PARENT_DIR_FOR_DATA
rsync -ah --delete --ignore-existing --exclude "*.pt" $ORIGINAL_DATA_PATH "$TMPDIR"/$TMP_PARENT_DIR_FOR_DATA/
echo "done with copying to scratch..."
date
ls "$TMPDIR"

num_workers=$(nproc --all)
echo "Num threads: $num_workers"


srun python3 -u -m module.script with workers=$num_workers train_path="$TMPDIR"/$TMP_PARENT_DIR_FOR_DATA
